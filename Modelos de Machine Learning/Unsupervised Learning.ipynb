{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0eb1226-9b2f-4cd3-b17c-7d1651b6e33b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Modelo de aprendizado não-supervisionado\n",
    "- Esse modelo é usado para encontrar padrões nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "906e7544-47c7-41ec-8740-0a99f46b638b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Load the iris dataset\n",
    "iris_bunch = datasets.load_iris()\n",
    "\n",
    "# Convert to DataFrame\n",
    "iris = pd.DataFrame(data=iris_bunch.data, columns=iris_bunch.feature_names)\n",
    "iris['species'] = iris_bunch.target\n",
    "\n",
    "iris_df = iris.drop(columns='species')\n",
    "# Print the 'species' column\n",
    "display(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5557322b-b27e-41dd-a7ee-5c26b70119fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(iris_df)\n",
    "rotulo = model.predict(iris_df) # fit_predict() é o mesmo que usar as duas funções\n",
    "\n",
    "centroid = model.cluster_centers_\n",
    "\n",
    "print(rotulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a52b969b-548a-48c5-83c3-352a33e2c426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "x = iris_df['sepal length (cm)']\n",
    "y = iris_df['petal length (cm)']\n",
    "plt.scatter(x,y,c=rotulo)\n",
    "\n",
    "plt.scatter(centroid[:,0],centroid[:,1],color='red',marker='D',s=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8534d34b-dc3a-4991-88ca-be17a94636a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Avaliando a qualidade de um cluster\n",
    "- Nesse caso, é possível comparar os conjuntos com as espécies de íris.\n",
    "Entretanto, na maioria dos casos, não terá rótulos nos datasets.\n",
    "- É necessário uma medida que utilize apenas os agrupamentos e as próprias amostras. --> **Inércia**\n",
    "\n",
    "- Inércia = A distância entre as amostras e seus centróides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de74214-432a-4c4e-be77-43b569c82b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'labels':rotulo,'species':iris['species']})\n",
    "\n",
    "ct = pd.crosstab(df['labels'], df['species'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51f424f1-a36e-434e-b392-b72ce0802dce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2455267-4708-441e-976c-e28711af659f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determinando a melhor inérica\n",
    "\n",
    "k = range(1,6)\n",
    "inercia = []\n",
    "\n",
    "for i in k:\n",
    "    model_c = KMeans(n_clusters=i)\n",
    "    model_c.fit(iris_df)\n",
    "    inercia.append(model_c.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(k,inercia,marker='o', color='purple')\n",
    "plt.xlabel('número de clusters')\n",
    "plt.ylabel('inércia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f06fbbb6-51a1-4e92-a6a8-92efa6f27351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Transformado features para melhor clusterização\n",
    "- Em alguns conjuntos de dados, os clusters não irão corresponder tão bem.\n",
    "- Isso pode acontecer se as features tiverem variâncias muito diferentes, como acontece com o dataset de vinhos do Piemonte.\n",
    "\n",
    "- A variância da feature corresponde à influência no algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfa4715b-aba5-4bb2-9ff4-aa205178fe45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o conjunto de dados dos vinhos\n",
    "wine_data = load_wine()\n",
    "wine_df = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "\n",
    "print(wine_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73d678a2-8e04-4b5f-91be-5f3bc18e45f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(wine_df)\n",
    "StandardScaler(copy=True,with_mean=True, with_std=True)\n",
    "amostra_normalizada = scaler.transform(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19a7c08f-b710-46eb-9279-61f8eec2912b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Também é possível fazer o mesmo usando pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming scaler and wine_df are defined somewhere in your code\n",
    "scaler = StandardScaler()\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "pipeline = make_pipeline(scaler, kmeans)\n",
    "pipeline.fit(wine_df)\n",
    "\n",
    "rotulo = pipeline.predict(wine_df)\n",
    "\n",
    "# Add the predicted labels to the DataFrame\n",
    "df = wine_df.copy()\n",
    "df['rotulo'] = rotulo\n",
    "\n",
    "# Create the crosstab\n",
    "ct = pd.crosstab(df['rotulo'], wine_data.target)\n",
    "display(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "818ce83b-e028-45a2-92e5-28f4e7956f75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## T-SNE e Hierarchical Clustering\n",
    "\n",
    "####Visualizando hierarquias:\n",
    "**Agrupamento Hierárquico:**\n",
    "- Grupos podem formar uma hierarquia, estando contidos uns nos outros.\n",
    "- É possível organizar qualquer tipo de dado em uma hierarquia.\n",
    "- Etapas:\n",
    "1. Cada grupo é separado em clusters.\n",
    "2. A cada passo, os 2 clusters mais próximos são mesclados.\n",
    "3. Continua mesclando até todos os grupos estarem juntos em um único cluster.\n",
    "\n",
    "- T-SNE = Cria um mapa 2D de um conjunto de dados e transmite informações sobre a proximidade das amostras umas das outras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0aadcc-a779-498b-81dd-52eb11ec1b83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv')\n",
    "\n",
    "# Agrupar por país e tirar a média dos votos (um país por linha)\n",
    "df_grouped = df.groupby(\"To country\")[[\"Jury A\", \"Jury B\", \"Jury C\", \"Jury D\", \"Jury E\", \"Jury Rank\", \"Televote Rank\"]].mean()\n",
    "\n",
    "# Aplicar o linkage\n",
    "mescla = linkage(df_grouped, method='complete')\n",
    "\n",
    "# Plotar o dendrograma\n",
    "plt.figure(figsize=(14,5))\n",
    "dendrogram(mescla, \n",
    "           labels=df_grouped.index.tolist(), \n",
    "           leaf_rotation=90, \n",
    "           leaf_font_size=12,\n",
    "           color_threshold=8\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66ac7a2c-6505-4f76-a130-8910e3135d41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Agrupamento hierárquico\n",
    "- É possível extrair cluster de estágios intermediários de um clustering hierárquico.\n",
    "- O estágio intermediário é especificado pela escolha de altura no dendograma.\n",
    "--> O eixo y é a distância entre os clusters mesclados.\n",
    "\n",
    "- A função fcluster() retorna um array com rótulos de cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77879701-987e-470f-8cdb-28bdca0c296c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "mescla = linkage(df_grouped, method='complete')\n",
    "\n",
    "rotulo = fcluster(mescla, 8, criterion='distance')\n",
    "\n",
    "print(rotulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7affb717-8904-44e4-99ff-4ec276b55057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pares = pd.DataFrame({'rotulo': rotulo, 'paises':df_grouped.index})\n",
    "print(pares.sort_values('rotulo')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5be37af-e496-4f73-a51a-f32bc9dea3d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### T-SNE \n",
    "- Siginifica **incorporação estocástica de vizinho distribuída em t**\n",
    "- Mapeia amostras de seu espaço de alta dimensão em um espaço bidimensional/tridimensional para que possam ser visualizadas.\n",
    "\n",
    "- A função fit_transform() faz o ajuste e a transformação.\n",
    "- Não possui métodos fit() e transform() separados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b796ab7-1157-437d-92d1-180fa817e7e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "amostra = iris.drop('species',axis=1)\n",
    "especies = iris['species']\n",
    "\n",
    "modelo = TSNE(learning_rate=100)\n",
    "transformado = modelo.fit_transform(amostra)\n",
    "\n",
    "xs = transformado[:,0]\n",
    "ys = transformado[:,1]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(xs,ys,c=especies)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbe022fd-efcc-4f32-aab8-1c40592fc9fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Redução de dimensionalidade (PCA)\n",
    "- PCA = Análise de Componentes Principais.\n",
    "- É constantemente usado antes do aprendizado supervisionado para melhorar o desempenho e generalização do modelo.\n",
    " \n",
    "- Pode ser usado para descartar features que geram ruídos.\n",
    "\n",
    "O PCA reduz a dimensionalidade em 2 etapas:\n",
    "1. Descorrelação:   \n",
    "--> Rotaciona as amostras mantendo elas alinhadas com os eixos de coordenadas.\n",
    "--> Desloca as amostrar para que a média seja 0.\n",
    "--> A informação não é perdida.\n",
    "2. Seleção de componentes principais\n",
    "--> Encontrar os componentes de maior variância (principais)\n",
    "--> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d9109b3-6fa5-43fd-ab30-735eef47b1d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "modelo = PCA()\n",
    "modelo.fit(amostra)\n",
    "\n",
    "transformado = modelo.transform(amostra)\n",
    "print(modelo.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aec01956-605f-44be-9a37-b0f746ba5b59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimensão intrínseca\n",
    "- É o número de características necessárias para aproximar o dataset. --> Features do PCA com variância significativa.\n",
    "- Diz o quanto um dataset pode ser compactado.\n",
    "- Quanto maior, mais informativo. As features de menor variância podem ser descartadas.\n",
    "\n",
    ".n_components_  \n",
    ".explained_variace_  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "452ce43c-34fd-43b9-b9d2-9b11c03f00ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "amostra = iris.drop('species',axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "pipeline = make_pipeline(scaler, pca)\n",
    "\n",
    "pipeline.fit_transform(amostra)\n",
    "\n",
    "features = range(pca.n_components_)\n",
    "\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xticks(features)\n",
    "plt.ylabel(\"Variância\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.show()\n",
    "\n",
    "#  dimensão intrínseca mais provável, com base neste gráfico, seria 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0ac1408-229e-4573-a6cd-bedae14ac1f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#n_components = Quantos recursos o modelo deve manter.\n",
    "# Se possível, escolher a dimensão intrínseca\n",
    "especies = iris['species']\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(amostra)\n",
    "\n",
    "transformado = pca.transform(amostra)\n",
    "\n",
    "xs = transformado[:,0]\n",
    "ys = transformado[:,1]\n",
    "\n",
    "plt.scatter(xs,ys,c=especies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eec8cd1e-4c52-47fe-8572-0110f7b845d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### NMF\n",
    "- NMF = Fatoração de Matrizes Não Negativas.\n",
    "- É uma técnica de redução de dimensionalidade\n",
    "\n",
    "- Decompõe amostras como somas de suas partes."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Unsupervised Learning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
